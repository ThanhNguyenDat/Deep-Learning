{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6051045e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "090a3457",
   "metadata": {},
   "source": [
    "# Learning Rate, Batch Size, and Other Hyperparameters\n",
    "The numbers of hidden layers and neurons are not only hyperparameters you can tweak in an Multi-layer Perceptron (MLP). Here are some of the most important ones, as well as tips on how to set them:\n",
    "\n",
    "* **Learning rate**: The learning rate is arguably the most important hyperparameter. In general, the optimal learning rate is about half of the maximum learning rate (i.e., the learning rate above which the training algorithm diverges). One way to find a good learning rate is to train the model for a few hundred iterations, starting with a very low learning rate (e.g., 10 ) and gradually increasing it up to a very large value (e.g., 10). This is done by multiplying the learning rate by a constant factor at each iteration (e.g., by exp(log(10 )/500) to go from 10 to 10 in 500 iterations). If you plot the loss as a function of the learning rate (using a log scale for the learning rate), you should see it dropping at first. But after a while, the learning rate will be too large, so the loss will shoot back up: the optimal learning rate will be a bit lower than the point at which the loss starts to climb (typically about 10 times lower than the turning point). You can then reinitialize your model and train it normally using this good learning rate.\n",
    "\n",
    "* **Optimizer**: Choosing a better optimizer than plain old Mini-batch Gradient Descent (and tuning its hyperparameters) is also quite important.\n",
    "\n",
    "* **Batch size**: The batch size can have a significant impact on your model’s performance and training time. The main benefit of using large batch sizes is that hardware accelerators like GPUs can process them efficiently, so the training algorithm will see more instances per second. Therefore, many researchers and practitioners recommend using the largest batch size that can fit in GPU RAM. There’s a catch, though: in practice, large batch sizes often lead to training instabilities, especially at the beginning of training, and the resulting model may not generalize as well as a model trained with a small batch size. So, one strategy is to try to use a large batch size, using learning rate warmup, and if training is unstable or the final performance is disappointing, then try using a small batch size instead. \n",
    "\n",
    "* **Activation functions**: We discussed how to choose the activation function earlier later.  In general, the ReLU activation function will be a good default for all hidden layers. For the output layer, it really depends on your task.\n",
    "\n",
    "* **Num of iterations**: In most cases, the number of training iterations does not actually need to be tweaked: just use early stopping instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cafb6a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992c6033",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9a07d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d7d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0903041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9854c5",
   "metadata": {},
   "source": [
    "This function creates a simple `Sequential` model for univariate regression (only one output neuron), with the given input shape and the given number of hidden layers and neurons, and it compiles it using an `SGD` optimizer configured with the specified learning rate. It is good practice to provide reasonable defaults to as many hyperparameters as you can, as Scikit-Learn\n",
    "does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2935e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92801b56",
   "metadata": {},
   "source": [
    "let’s create a `KerasRegressor` based on this `build_model()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f146e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cce4b",
   "metadata": {},
   "source": [
    "Now we can use this object like a regular Scikit-Learn regressor: we can train it using its `fit()` method, then evaluate it using its `score()` method, and use it to make predictions using its `predict()` method, as you can see in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c858959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.5673 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3216 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5972 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4985 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4608 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4139 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3992 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3948 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3473\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3921\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3722\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3547 - val_loss: 0.3454\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 0.3660\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3597 - val_loss: 0.3766\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3443 - val_loss: 0.3814\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.3657\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.3576\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.3358\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.3317\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3564\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3427 - val_loss: 0.3522\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.4581\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3808\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.3539\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.3721\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.3336\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3414 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3621 - val_loss: 0.3348\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3497 - val_loss: 0.3492\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.3401\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3299 - val_loss: 0.3274\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.3296\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.3307\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3242\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3350 - val_loss: 0.3659\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3428 - val_loss: 0.3379\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3261 - val_loss: 0.3272\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3242\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3661\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3284\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3390 - val_loss: 0.3243\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3372\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c70cacca08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648ce12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3412\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60c614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a2fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36233b",
   "metadata": {},
   "source": [
    "We don’t want to train and evaluate a single model like this, though we want to train hundreds of variants and see which one performs best on the validation set. Since there are many hyperparameters, it is preferable to use a randomized search rather than grid search. Let’s try to explore the number of hidden layers, the number of neurons, and the learning rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe84ed7",
   "metadata": {},
   "source": [
    "**Warning**: the following cell crashes at the end of training. This seems to be caused by [Keras issue #13586](https://github.com/keras-team/keras/issues/13586), which was triggered by a recent change in Scikit-Learn. [Pull Request #13598](https://github.com/keras-team/keras/pull/13598) seems to fix the issue, so this problem should be resolved soon. In the meantime, I've added `.tolist()` and `.rvs(1000).tolist()` as workarounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c07228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3827 - val_loss: 0.4703\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4880 - val_loss: 0.4247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4541 - val_loss: 0.4052\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4518 - val_loss: 0.3975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4337 - val_loss: 0.3991\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4301 - val_loss: 0.3929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4040\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4200 - val_loss: 0.3886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.3999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.3922\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.3886\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.3933\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.3935\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.3891\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  13.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3852 - val_loss: 0.4860\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4722 - val_loss: 0.4280\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4384 - val_loss: 0.5791\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4527 - val_loss: 0.5250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4474 - val_loss: 0.5486\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.5871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4759\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4299 - val_loss: 0.7523\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4390 - val_loss: 0.7478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4395 - val_loss: 0.8981\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4234 - val_loss: 0.8543\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4537\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   8.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 13.5523 - val_loss: 4.2476\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2460 - val_loss: 0.5794\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5520 - val_loss: 0.4357\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4507 - val_loss: 0.4169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4365 - val_loss: 0.4135\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.4206\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4420 - val_loss: 0.4100\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4636 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4411 - val_loss: 0.4111\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4840 - val_loss: 0.4076\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4626 - val_loss: 0.4062\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4326 - val_loss: 0.4078\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4226 - val_loss: 0.4160\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4260 - val_loss: 0.4158\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4551 - val_loss: 0.4137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4552 - val_loss: 0.4069\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4343 - val_loss: 0.4119\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4453 - val_loss: 0.4149\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4530 - val_loss: 0.4081\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4502 - val_loss: 0.4141\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4420 - val_loss: 0.4100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4473\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  16.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.7737 - val_loss: 6.2480\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5899 - val_loss: 5.2166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5147 - val_loss: 0.4474\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4477 - val_loss: 0.3901\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3980 - val_loss: 0.3736\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3757 - val_loss: 0.3803\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3701 - val_loss: 0.3813\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3961\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3512 - val_loss: 0.3988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3358 - val_loss: 0.3870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3252 - val_loss: 0.3769\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3499 - val_loss: 0.3770\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3848\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3331 - val_loss: 0.3768\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3560\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  14.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.5396 - val_loss: 3.5738\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5129 - val_loss: 0.7767\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4283 - val_loss: 0.5515\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4097 - val_loss: 0.5335\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3926 - val_loss: 0.5336\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3760 - val_loss: 0.6750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3580 - val_loss: 0.8462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3622 - val_loss: 0.8724\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3518 - val_loss: 0.9645\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3560 - val_loss: 0.7225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3517 - val_loss: 0.7257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3367 - val_loss: 0.7217\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3334 - val_loss: 0.8443\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3244 - val_loss: 0.7065\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3650\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  13.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.7832 - val_loss: 2.9433\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5594 - val_loss: 4.2557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4797 - val_loss: 2.8526\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4774 - val_loss: 1.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4322\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3736 - val_loss: 0.4172\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3719 - val_loss: 0.3769\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3883 - val_loss: 0.3688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.4032\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.3418\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4452\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3487 - val_loss: 0.3454\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3258 - val_loss: 0.3395\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.4354\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.3386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3302\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.3580\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3546\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.3460\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3327 - val_loss: 0.3244\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3455 - val_loss: 0.3257\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3303 - val_loss: 0.3441\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3377\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3196 - val_loss: 0.3651\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3924\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3141\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3201\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.4308\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3203 - val_loss: 0.3204\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3092 - val_loss: 0.3129\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.4282\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3194 - val_loss: 0.3116\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3035 - val_loss: 0.3920\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3110 - val_loss: 0.4133\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3005 - val_loss: 0.6989\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3116 - val_loss: 0.7472\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 1.0275\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.4151\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 0.6727\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3022 - val_loss: 0.3498\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2983 - val_loss: 0.7570\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3140 - val_loss: 0.8347\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3180\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  36.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.2328 - val_loss: 13.3699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4156 - val_loss: 10.8972\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4953 - val_loss: 7.7330\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1092 - val_loss: 5.0744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8935 - val_loss: 3.2363\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8194 - val_loss: 2.1597\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7802 - val_loss: 1.4840\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7285 - val_loss: 1.1083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6921 - val_loss: 0.8942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6951 - val_loss: 0.7687\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6599 - val_loss: 0.6947\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6237 - val_loss: 0.6524\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6619 - val_loss: 0.6234\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6487 - val_loss: 0.6061\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6429 - val_loss: 0.5933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6103 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6492 - val_loss: 0.5733\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6227 - val_loss: 0.5650\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6024 - val_loss: 0.5578\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5992 - val_loss: 0.5508\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5874 - val_loss: 0.5446\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5653 - val_loss: 0.5384\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5863 - val_loss: 0.5326\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5689 - val_loss: 0.5214\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5438 - val_loss: 0.5166\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5653 - val_loss: 0.5116\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5540 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5635 - val_loss: 0.5035\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5438 - val_loss: 0.4989\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5203 - val_loss: 0.4946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5238 - val_loss: 0.4915\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5159 - val_loss: 0.4883\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5200 - val_loss: 0.4856\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5080 - val_loss: 0.4828\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.4789\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5136 - val_loss: 0.4780\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4794 - val_loss: 0.4742\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5037 - val_loss: 0.4729\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4797 - val_loss: 0.4714\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4870 - val_loss: 0.4686\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.4666\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4892 - val_loss: 0.4646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4786 - val_loss: 0.4636\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4812 - val_loss: 0.4616\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4710 - val_loss: 0.4582\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4787 - val_loss: 0.4581\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4574 - val_loss: 0.4573\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4752 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4641 - val_loss: 0.4544\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4536 - val_loss: 0.4525\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4800 - val_loss: 0.4527\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4622 - val_loss: 0.4522\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4648 - val_loss: 0.4509\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4387 - val_loss: 0.4509\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4897 - val_loss: 0.4513\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4494 - val_loss: 0.4496\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4645 - val_loss: 0.4510\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4580 - val_loss: 0.4502\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4393 - val_loss: 0.4478\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4271 - val_loss: 0.4485\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4362 - val_loss: 0.4488\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4499 - val_loss: 0.4477\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 0.4497\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4512\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4718 - val_loss: 0.4484\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4375 - val_loss: 0.4483\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4390 - val_loss: 0.4494\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4492\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4546 - val_loss: 0.4476\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4346 - val_loss: 0.4481\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4486 - val_loss: 0.4503\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4463 - val_loss: 0.4486\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4312 - val_loss: 0.4491\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4328 - val_loss: 0.4496\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4483\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4474\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4495\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4468\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.4492\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4525\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.4504\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4320 - val_loss: 0.4525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4495\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4512\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4481\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4472\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4506\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4209\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time= 1.1min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.4546 - val_loss: 7.5238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7950 - val_loss: 8.6120\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1115 - val_loss: 8.4896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9287 - val_loss: 7.7423\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8253 - val_loss: 6.8202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7837 - val_loss: 5.9344\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7711 - val_loss: 5.1492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7292 - val_loss: 4.4548\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7279 - val_loss: 3.9122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7055 - val_loss: 3.4233\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6956 - val_loss: 2.9997\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6640 - val_loss: 2.6082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6539 - val_loss: 2.2766\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6447 - val_loss: 1.9984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6831 - val_loss: 1.7447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6364 - val_loss: 1.5300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6425 - val_loss: 1.3410\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6340 - val_loss: 1.1762\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6140 - val_loss: 1.0345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6101 - val_loss: 0.9174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5938 - val_loss: 0.8153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5975 - val_loss: 0.7363\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5957 - val_loss: 0.6696\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5714 - val_loss: 0.6187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5535 - val_loss: 0.5778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5553 - val_loss: 0.5491\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5725 - val_loss: 0.5299\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5688 - val_loss: 0.5199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5619 - val_loss: 0.5172\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5510 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5401 - val_loss: 0.5312\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5370 - val_loss: 0.5447\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5423 - val_loss: 0.5639\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5211 - val_loss: 0.5821\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5081 - val_loss: 0.6039\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5036 - val_loss: 0.6306\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5191 - val_loss: 0.6564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4928 - val_loss: 0.6820\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5096 - val_loss: 0.7087\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5160\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  29.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.8993 - val_loss: 7.4460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4173 - val_loss: 5.2071\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4701 - val_loss: 2.9554\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1716 - val_loss: 1.7752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9242 - val_loss: 1.1201\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8307 - val_loss: 0.8519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7780 - val_loss: 0.7512\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7632 - val_loss: 0.7064\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7361 - val_loss: 0.6896\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6859 - val_loss: 0.6760\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7064 - val_loss: 0.6687\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6826 - val_loss: 0.6577\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6416 - val_loss: 0.6454\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6539 - val_loss: 0.6355\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6736 - val_loss: 0.6256\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6529 - val_loss: 0.6213\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6253 - val_loss: 0.6120\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6484 - val_loss: 0.6024\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6228 - val_loss: 0.5998\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6079 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5912 - val_loss: 0.5822\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6250 - val_loss: 0.5763\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5804 - val_loss: 0.5664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5735 - val_loss: 0.5574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5793 - val_loss: 0.5527\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5576 - val_loss: 0.5452\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5786 - val_loss: 0.5437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5683 - val_loss: 0.5366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5475 - val_loss: 0.5322\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5471 - val_loss: 0.5264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5281 - val_loss: 0.5234\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5547 - val_loss: 0.5175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5437 - val_loss: 0.5137\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5113 - val_loss: 0.5078\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5125 - val_loss: 0.5045\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5127 - val_loss: 0.4970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5158 - val_loss: 0.4911\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5132 - val_loss: 0.4887\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5140 - val_loss: 0.4847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4995 - val_loss: 0.4815\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4795 - val_loss: 0.4776\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4838 - val_loss: 0.4736\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4966 - val_loss: 0.4706\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.4673\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4810 - val_loss: 0.4655\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4737 - val_loss: 0.4625\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4866 - val_loss: 0.4576\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4719 - val_loss: 0.4554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4859 - val_loss: 0.4525\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4618 - val_loss: 0.4495\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4862 - val_loss: 0.4468\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4576 - val_loss: 0.4446\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4641 - val_loss: 0.4420\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4641 - val_loss: 0.4394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4560 - val_loss: 0.4373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4620 - val_loss: 0.4349\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4542 - val_loss: 0.4330\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4659 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4584 - val_loss: 0.4291\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4684 - val_loss: 0.4277\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4678 - val_loss: 0.4257\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4516 - val_loss: 0.4241\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4410 - val_loss: 0.4224\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4622 - val_loss: 0.4208\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 0.4193\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4354 - val_loss: 0.4180\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4504 - val_loss: 0.4151\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4247 - val_loss: 0.4141\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4433 - val_loss: 0.4124\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4618 - val_loss: 0.4112\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4101\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4359 - val_loss: 0.4088\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4307 - val_loss: 0.4081\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4273 - val_loss: 0.4073\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4386 - val_loss: 0.4070\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4324 - val_loss: 0.4056\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4313 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4328 - val_loss: 0.4034\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4033\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4019\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4008\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4002\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4320 - val_loss: 0.3996\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4259 - val_loss: 0.3983\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.3980\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4237 - val_loss: 0.3981\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.3969\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4303 - val_loss: 0.3978\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.3961\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.3951\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.3938\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.3938\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.3935\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.3934\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.3932\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.3939\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.3913\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.3916\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.3918\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4139\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time= 1.2min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.4453 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7645 - val_loss: 0.7463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6590 - val_loss: 0.5899\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6064 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5580 - val_loss: 0.5063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5150 - val_loss: 0.4813\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4985 - val_loss: 0.4639\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4716 - val_loss: 0.4427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4477 - val_loss: 0.4393\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4411 - val_loss: 0.4137\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4204 - val_loss: 0.4071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3978 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4290 - val_loss: 0.3933\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.3972\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.3830\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.3947\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.3713\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3829 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3867 - val_loss: 0.3741\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3800 - val_loss: 0.3782\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3686 - val_loss: 0.3637\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3795 - val_loss: 0.3723\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3691 - val_loss: 0.3707\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3751 - val_loss: 0.4047\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3599 - val_loss: 0.3839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3795 - val_loss: 0.4167\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.3500\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.3792\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.3636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.3476\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3566\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3517 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3521 - val_loss: 0.3414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.3474\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3944\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.4401\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3539 - val_loss: 0.4721\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3449 - val_loss: 0.3722\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3307 - val_loss: 0.4019\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3408 - val_loss: 0.3376\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.3377\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3436 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3430 - val_loss: 0.3737\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3306 - val_loss: 0.3563\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3370 - val_loss: 0.3547\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3399\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.3304\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3347 - val_loss: 0.3850\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3430\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3363\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3329 - val_loss: 0.3386\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3366 - val_loss: 0.3294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3260 - val_loss: 0.3655\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3558 - val_loss: 0.3310\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3366 - val_loss: 0.3730\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3374 - val_loss: 0.3375\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3415 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3332 - val_loss: 0.3403\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3199 - val_loss: 0.3436\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3275 - val_loss: 0.3583\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3341 - val_loss: 0.3306\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3222 - val_loss: 0.3679\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3298\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3518 - val_loss: 0.3272\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3314 - val_loss: 0.3565\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3287 - val_loss: 0.3295\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3316 - val_loss: 0.3440\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3550\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time= 1.0min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.2276 - val_loss: 3.4090\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7673 - val_loss: 1.6754\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6369 - val_loss: 0.9319\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6031 - val_loss: 0.6042\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5652 - val_loss: 0.5061\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5258 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4977 - val_loss: 0.5272\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4759 - val_loss: 0.5600\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4640 - val_loss: 0.5367\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4464 - val_loss: 0.5221\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4347 - val_loss: 0.4878\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.3877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.3818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4022\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3999 - val_loss: 0.4348\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4069 - val_loss: 0.4935\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3895 - val_loss: 0.5340\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.5982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.6541\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.7245\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.8045\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.8587\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.9089\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3884\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  21.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.3058 - val_loss: 2.1643\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7651 - val_loss: 0.6141\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6136 - val_loss: 0.5601\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5596 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5017\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 0.4749\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4781 - val_loss: 0.4558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4755 - val_loss: 0.4297\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4463 - val_loss: 0.4464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4310 - val_loss: 0.4189\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4329 - val_loss: 0.4438\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4250\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.4009\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4403\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4014\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3992 - val_loss: 0.4247\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.3964\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.3974\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3901 - val_loss: 0.4053\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.3989\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.3864\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.4022\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.3729\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4107\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.3925\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3648 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.3879\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.3789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.4080\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3873\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4232\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.3718\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3555\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  29.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9995 - val_loss: 297.3652\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2481 - val_loss: 539.0366\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.5441 - val_loss: 3736.4507\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7.4651 - val_loss: 12227.6982\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 22.4715 - val_loss: 61529.1016\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2537.2822 - val_loss: 268363.5625\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2132.8536 - val_loss: 1210517.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 32696.8284 - val_loss: 5411004.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 28036.3041 - val_loss: 24506690.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 910066.2422 - val_loss: 119813024.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1721897.4547 - val_loss: 529731008.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1402365.2500\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   7.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2323 - val_loss: 15.8284\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5228 - val_loss: 22.4892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 24.7894\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5081 - val_loss: 22.4864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5095 - val_loss: 21.9009\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5093 - val_loss: 21.2895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4936 - val_loss: 19.9064\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5221 - val_loss: 22.5013\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5027 - val_loss: 20.0987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4831 - val_loss: 10.7128\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5128 - val_loss: 19.7319\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4957 - val_loss: 24.3237\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5081 - val_loss: 25.9485\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4740 - val_loss: 10.5277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5379 - val_loss: 17.1916\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5078 - val_loss: 21.8347\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4993 - val_loss: 11.7743\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5211 - val_loss: 14.1555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5103 - val_loss: 20.9814\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4812 - val_loss: 12.3621\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5134 - val_loss: 25.9146\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4890 - val_loss: 16.0461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5148 - val_loss: 19.4877\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4909 - val_loss: 12.1054\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7813\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  16.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9669 - val_loss: 307.7496\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0908 - val_loss: 76.3015\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8437 - val_loss: 795.2292\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 41.8219 - val_loss: 704.0450\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0379 - val_loss: 2668.0286\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6.1716 - val_loss: 1446.2605\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3018 - val_loss: 1540.5377\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 71.5700 - val_loss: 1396.7115\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6.0212 - val_loss: 1334.0847\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.0299 - val_loss: 216.7268\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 21.3465 - val_loss: 125.2065\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7510 - val_loss: 2.2902\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4922 - val_loss: 790.5424\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.4409 - val_loss: 468.7424\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0499 - val_loss: 1073.9149\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 45.2524 - val_loss: 865.6385\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7759 - val_loss: 1128.1501\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7236 - val_loss: 499.5191\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 34.6839 - val_loss: 309.7941\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3475 - val_loss: 354.6341\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4646 - val_loss: 559.4488\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.0812 - val_loss: 393.8696\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.6226\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  14.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9862 - val_loss: 1.4543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6404 - val_loss: 0.9557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5532 - val_loss: 0.4628\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4956 - val_loss: 0.4214\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4377 - val_loss: 0.3984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4056\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4015 - val_loss: 0.3741\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3915 - val_loss: 0.3926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3725 - val_loss: 0.3832\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3731 - val_loss: 0.3929\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.3570\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.3790\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.3840\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3560 - val_loss: 0.3950\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.3955\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3559 - val_loss: 0.3900\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3621 - val_loss: 0.3905\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3365 - val_loss: 0.3944\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3438 - val_loss: 0.3811\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3389 - val_loss: 0.3906\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3624\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  18.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.7235 - val_loss: 0.5822\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5852 - val_loss: 0.4873\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4784 - val_loss: 0.4420\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4436 - val_loss: 0.4139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4223 - val_loss: 0.4132\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3955 - val_loss: 0.4464\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3768 - val_loss: 0.4717\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3800 - val_loss: 0.5331\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3620 - val_loss: 0.6951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3645 - val_loss: 0.6944\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3646 - val_loss: 0.8506\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3432 - val_loss: 0.7660\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3419 - val_loss: 0.8731\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3305 - val_loss: 0.9306\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3605 - val_loss: 0.9345\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3685\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  13.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.7434 - val_loss: 0.6796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5868 - val_loss: 0.4957\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5017 - val_loss: 0.4633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4473 - val_loss: 0.4565\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4218 - val_loss: 0.4150\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3928 - val_loss: 0.4331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3924 - val_loss: 0.3887\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.3785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.4233\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.3652\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3866 - val_loss: 0.4336\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3635 - val_loss: 0.3763\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3414 - val_loss: 0.3632\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3498 - val_loss: 0.4460\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3760 - val_loss: 0.3555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3554 - val_loss: 0.3947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3443 - val_loss: 0.3623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3532 - val_loss: 0.3774\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3664 - val_loss: 0.3806\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3544 - val_loss: 0.3420\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3428 - val_loss: 0.3452\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.3273\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3386 - val_loss: 0.3279\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.4328\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3306 - val_loss: 0.3426\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3298 - val_loss: 0.3228\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3435 - val_loss: 0.4407\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3301\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3288 - val_loss: 0.4053\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3297 - val_loss: 0.3360\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3188 - val_loss: 0.3330\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3392 - val_loss: 0.3658\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3285 - val_loss: 0.3479\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3120 - val_loss: 0.3596\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3144 - val_loss: 0.3131\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3094 - val_loss: 0.3617\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3215 - val_loss: 0.3386\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3191 - val_loss: 0.5222\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3300 - val_loss: 0.3333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3192 - val_loss: 0.4050\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3023 - val_loss: 0.3326\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3030 - val_loss: 0.3593\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3221 - val_loss: 0.3245\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3249 - val_loss: 0.3830\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3108 - val_loss: 0.3084\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3079 - val_loss: 0.3726\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3160\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3054 - val_loss: 0.3005\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3112 - val_loss: 0.4075\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3104 - val_loss: 0.2996\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3180 - val_loss: 0.4364\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3030 - val_loss: 0.3002\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3062 - val_loss: 0.2985\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3021 - val_loss: 0.2960\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3003 - val_loss: 0.2948\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3071 - val_loss: 0.3314\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3001 - val_loss: 0.3077\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3082 - val_loss: 0.2979\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3090 - val_loss: 0.3541\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3084 - val_loss: 0.3919\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3144 - val_loss: 0.3128\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3002 - val_loss: 0.3066\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3010 - val_loss: 0.2950\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3148 - val_loss: 0.3041\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2976 - val_loss: 0.2944\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2886 - val_loss: 0.3637\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2994 - val_loss: 0.3032\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3084 - val_loss: 0.3324\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2923 - val_loss: 0.2901\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2912 - val_loss: 0.3183\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3069 - val_loss: 0.2875\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2800 - val_loss: 0.2920\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2990 - val_loss: 0.2932\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2940 - val_loss: 0.2857\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2926 - val_loss: 0.3148\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2938 - val_loss: 0.3570\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3112 - val_loss: 0.2876\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2991 - val_loss: 0.3106\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2931 - val_loss: 0.2915\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2881 - val_loss: 0.2879\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2852 - val_loss: 0.3139\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2797 - val_loss: 0.3076\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2823 - val_loss: 0.2900\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2972 - val_loss: 0.3418\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3057\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time= 1.3min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.4800 - val_loss: 29.5063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8491 - val_loss: 33.7784\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8416 - val_loss: 4.0125\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6237 - val_loss: 0.5556\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5755 - val_loss: 0.5119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5306 - val_loss: 0.4888\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.4729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4973 - val_loss: 0.4559\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4747 - val_loss: 0.4601\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4664 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4450 - val_loss: 0.4205\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4480 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4328 - val_loss: 0.4231\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4293 - val_loss: 0.4221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4155 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4334 - val_loss: 0.4209\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4284 - val_loss: 0.4017\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4001\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4032\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4039\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.3764\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4241\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3863 - val_loss: 0.3779\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4126\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3956 - val_loss: 0.3967\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3863 - val_loss: 0.3717\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.3676\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.3924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3782 - val_loss: 0.3611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.4182\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4403\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.3551\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4125\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.3665\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.3591\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3709 - val_loss: 0.3570\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.4125\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.3547\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.3779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.3886\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3877\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  35.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3075 - val_loss: 0.7805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7479 - val_loss: 1.1550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6249 - val_loss: 1.8115\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5885 - val_loss: 2.6113\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5412 - val_loss: 3.2626\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5083 - val_loss: 3.5247\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4786 - val_loss: 3.5926\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4660 - val_loss: 3.5562\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4559 - val_loss: 2.9541\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4427 - val_loss: 2.5606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4424 - val_loss: 2.1560\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4866\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   9.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9276 - val_loss: 2.5834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7344 - val_loss: 3.5564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6461 - val_loss: 1.7895\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6260 - val_loss: 1.7436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5519 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5085 - val_loss: 0.8713\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5055 - val_loss: 0.5604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 0.4695\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4772 - val_loss: 0.4942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4582 - val_loss: 0.4375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4637 - val_loss: 0.4536\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4395 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4219 - val_loss: 0.4897\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4455 - val_loss: 0.4018\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.5505\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4250 - val_loss: 0.4347\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.3835\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4115\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.3737\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.3720\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4318\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4158\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.3821\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4069\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4024\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.5904\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3872 - val_loss: 0.4027\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.4216\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.3603\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4134\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.3633\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.3542\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3710 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4216\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3764 - val_loss: 0.5522\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3867 - val_loss: 0.5648\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3818 - val_loss: 0.6416\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.3847\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.5255\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.7023\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.7507\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.5608\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3745\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  34.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.6933 - val_loss: 6.4183\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6124 - val_loss: 16.7917\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5548 - val_loss: 4.7823\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4575 - val_loss: 8.6076\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4166 - val_loss: 1.8025\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.3655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.3786\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3529 - val_loss: 0.4054\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3455 - val_loss: 0.3910\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3489 - val_loss: 0.3912\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3307 - val_loss: 0.3550\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3169 - val_loss: 0.3612\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3465 - val_loss: 0.3650\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3625\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3251 - val_loss: 0.3565\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3238 - val_loss: 0.3558\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3329 - val_loss: 0.3555\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3388 - val_loss: 0.3500\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3133 - val_loss: 0.3504\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3201 - val_loss: 0.3392\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3365\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.3693\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3152 - val_loss: 0.3195\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3079 - val_loss: 0.3087\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3103 - val_loss: 0.3589\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2953 - val_loss: 0.3122\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3126 - val_loss: 0.3275\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3059 - val_loss: 0.3536\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2989 - val_loss: 0.3315\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2989 - val_loss: 0.2960\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2952 - val_loss: 0.3122\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2850 - val_loss: 0.2887\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2896 - val_loss: 0.3220\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2832 - val_loss: 0.3172\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2852 - val_loss: 0.2943\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.3723\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2762 - val_loss: 0.3260\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2937 - val_loss: 0.3555\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2786 - val_loss: 0.2923\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2666 - val_loss: 0.3324\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2757 - val_loss: 0.2885\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2772 - val_loss: 0.2909\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2787 - val_loss: 0.2860\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2744 - val_loss: 0.3188\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2797 - val_loss: 0.3108\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2669 - val_loss: 0.3249\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2682 - val_loss: 0.2890\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2661 - val_loss: 0.2840\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2789 - val_loss: 0.2777\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2637 - val_loss: 0.3328\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2594 - val_loss: 0.3179\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2770 - val_loss: 0.3177\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2644 - val_loss: 0.2842\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2579 - val_loss: 0.2830\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2578 - val_loss: 0.2988\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2762 - val_loss: 0.2723\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2707 - val_loss: 0.3335\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2638 - val_loss: 0.2753\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2688 - val_loss: 0.2905\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2565 - val_loss: 0.2812\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2555 - val_loss: 0.3755\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2585 - val_loss: 0.2795\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.3285\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2527 - val_loss: 0.2762\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2456 - val_loss: 0.3070\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2658 - val_loss: 0.3185\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3105\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  58.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.4417 - val_loss: 0.7369\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5298 - val_loss: 0.4431\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4286 - val_loss: 0.3919\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4017 - val_loss: 0.3834\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.3951\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3655 - val_loss: 0.4650\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3497 - val_loss: 0.6408\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3530 - val_loss: 0.7273\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.9104\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3458 - val_loss: 0.6969\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3395 - val_loss: 0.6999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3255 - val_loss: 0.7835\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3186 - val_loss: 0.8539\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3123 - val_loss: 0.8282\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3525\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  12.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.6880 - val_loss: 0.9196\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4943 - val_loss: 2.1030\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4287 - val_loss: 3.5546\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4622 - val_loss: 1.5870\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3734 - val_loss: 0.4229\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.3736\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.3347\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.3389\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3478 - val_loss: 0.3714\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3271\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3648 - val_loss: 0.3873\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3351 - val_loss: 0.3337\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3090 - val_loss: 0.3220\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3691\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.3202\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3247 - val_loss: 0.3598\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3123 - val_loss: 0.3241\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3224 - val_loss: 0.3532\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3343 - val_loss: 0.3357\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3247 - val_loss: 0.3616\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3146 - val_loss: 0.3152\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3259 - val_loss: 0.3175\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3107 - val_loss: 0.3580\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3026 - val_loss: 0.3041\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3000 - val_loss: 0.3216\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2991 - val_loss: 0.3245\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3137 - val_loss: 0.3125\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3100 - val_loss: 0.3490\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.3862\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3017 - val_loss: 0.3183\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2897 - val_loss: 0.3122\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3075 - val_loss: 0.3014\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.3222\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2851 - val_loss: 0.3020\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2829 - val_loss: 0.2965\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2783 - val_loss: 0.4448\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2897 - val_loss: 0.3683\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2971 - val_loss: 0.4166\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3000 - val_loss: 0.2964\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2860 - val_loss: 0.3617\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2701 - val_loss: 0.3154\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2794 - val_loss: 0.3138\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.2842\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2907 - val_loss: 0.3241\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2735 - val_loss: 0.2951\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2757 - val_loss: 0.3328\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2777 - val_loss: 0.2820\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2722 - val_loss: 0.2838\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2812 - val_loss: 0.3641\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2801 - val_loss: 0.2970\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2822 - val_loss: 0.3488\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2687 - val_loss: 0.2949\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2792 - val_loss: 0.2940\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2743 - val_loss: 0.2973\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2671 - val_loss: 0.2806\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2779 - val_loss: 0.3015\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2729 - val_loss: 0.3550\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.2928\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2761 - val_loss: 0.3158\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2747 - val_loss: 0.2777\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2770 - val_loss: 0.3425\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2678 - val_loss: 0.2753\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2641 - val_loss: 0.3171\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2788 - val_loss: 0.2864\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2643 - val_loss: 0.2885\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2560 - val_loss: 0.2939\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2685 - val_loss: 0.2901\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.2933\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2779\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2585 - val_loss: 0.2849\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2741 - val_loss: 0.2742\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2502 - val_loss: 0.2750\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2670 - val_loss: 0.2925\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2631 - val_loss: 0.2811\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2607 - val_loss: 0.2931\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2554 - val_loss: 0.3316\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2741 - val_loss: 0.2795\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2643 - val_loss: 0.4124\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2613 - val_loss: 0.2784\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2572 - val_loss: 0.2716\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2463 - val_loss: 0.2975\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2483 - val_loss: 0.2786\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2522 - val_loss: 0.3338\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2647 - val_loss: 0.2742\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2563 - val_loss: 0.2930\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2495 - val_loss: 0.2810\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2570 - val_loss: 0.3121\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2450 - val_loss: 0.2711\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.2792\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2502 - val_loss: 0.3115\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2664 - val_loss: 0.2751\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2520 - val_loss: 0.2695\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2474 - val_loss: 0.2903\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.2842\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2589 - val_loss: 0.3035\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2458 - val_loss: 0.3096\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2473 - val_loss: 0.2928\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2456 - val_loss: 0.3358\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2378 - val_loss: 0.2702\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2383 - val_loss: 0.2945\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.2939\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time= 1.4min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.5786 - val_loss: 10.9250\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5353 - val_loss: 3.3912\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4521 - val_loss: 0.4039\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4084 - val_loss: 0.3692\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3670 - val_loss: 0.3555\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3524 - val_loss: 0.3875\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3487 - val_loss: 0.3633\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3423 - val_loss: 0.3991\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3333 - val_loss: 0.3797\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3379 - val_loss: 0.3704\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3209 - val_loss: 0.3310\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3109 - val_loss: 0.3509\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3374 - val_loss: 0.3795\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3224 - val_loss: 0.3311\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3175 - val_loss: 0.3491\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3173 - val_loss: 0.3473\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3261 - val_loss: 0.3259\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3418\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3066 - val_loss: 0.3327\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3129 - val_loss: 0.3266\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3090 - val_loss: 0.3732\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3027 - val_loss: 0.3087\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3061 - val_loss: 0.3960\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3051 - val_loss: 0.3903\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3110 - val_loss: 0.3345\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2909 - val_loss: 0.3226\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3087 - val_loss: 0.3266\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3002 - val_loss: 0.4213\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2943 - val_loss: 0.3040\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2946 - val_loss: 0.2987\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2926 - val_loss: 0.3067\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2938\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2864 - val_loss: 0.3369\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2809 - val_loss: 0.3338\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2804 - val_loss: 0.2913\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2831 - val_loss: 0.3635\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2733 - val_loss: 0.3303\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2924 - val_loss: 0.3682\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2793 - val_loss: 0.2938\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2641 - val_loss: 0.3416\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2756 - val_loss: 0.2859\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2759 - val_loss: 0.3175\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2774 - val_loss: 0.2921\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2711 - val_loss: 0.3232\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2752 - val_loss: 0.2796\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2630 - val_loss: 0.3144\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2669 - val_loss: 0.3168\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2623 - val_loss: 0.3099\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2782 - val_loss: 0.2804\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2651 - val_loss: 0.3781\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2553 - val_loss: 0.3156\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2738 - val_loss: 0.3562\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2598 - val_loss: 0.2884\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2533 - val_loss: 0.3015\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2567 - val_loss: 0.2914\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3096\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  48.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.5488 - val_loss: 0.6551\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4745 - val_loss: 0.4129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.6096\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3959 - val_loss: 0.6534\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.6227\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3631 - val_loss: 0.8403\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3493 - val_loss: 1.0599\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 1.1357\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3392 - val_loss: 1.2306\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3463 - val_loss: 0.8012\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3414 - val_loss: 0.8288\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.7655\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3590\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  10.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.4295 - val_loss: 2.2007\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5148 - val_loss: 3.3028\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4423 - val_loss: 0.9130\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.5328\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3757 - val_loss: 0.3609\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3528 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.3580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.3516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3488 - val_loss: 0.3983\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3449 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4233\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3353 - val_loss: 0.3284\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3110 - val_loss: 0.3469\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3199 - val_loss: 0.4037\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3410 - val_loss: 0.3269\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.3776\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3215\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3198 - val_loss: 0.3289\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3349 - val_loss: 0.3861\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3155 - val_loss: 0.3954\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3277 - val_loss: 0.3162\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3096 - val_loss: 0.3483\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3033 - val_loss: 0.3197\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3004 - val_loss: 0.3071\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3016 - val_loss: 0.3091\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3128 - val_loss: 0.4026\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3128 - val_loss: 0.3323\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3012 - val_loss: 0.3773\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2999 - val_loss: 0.3524\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2885 - val_loss: 0.3063\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3076 - val_loss: 0.4479\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2981 - val_loss: 0.3099\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2845 - val_loss: 0.3688\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.3005\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2805 - val_loss: 0.3865\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2904 - val_loss: 0.3046\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2895 - val_loss: 0.3832\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3009 - val_loss: 0.2934\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.3557\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.3303\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2760 - val_loss: 0.4287\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2899 - val_loss: 0.3025\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2946 - val_loss: 0.3580\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2789 - val_loss: 0.2973\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2760 - val_loss: 0.3387\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2768 - val_loss: 0.2834\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2713 - val_loss: 0.2920\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2776 - val_loss: 0.4260\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2773 - val_loss: 0.3424\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2826 - val_loss: 0.4973\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2665 - val_loss: 0.3619\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2752 - val_loss: 0.3058\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2726 - val_loss: 0.3160\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2667 - val_loss: 0.2864\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2728 - val_loss: 0.4389\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2703 - val_loss: 0.2829\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2788 - val_loss: 0.3853\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2730 - val_loss: 0.3173\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2741 - val_loss: 0.2824\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2759 - val_loss: 0.3398\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2637 - val_loss: 0.2955\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.3129\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2800 - val_loss: 0.3233\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2632 - val_loss: 0.2832\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2552 - val_loss: 0.3293\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2646 - val_loss: 0.2926\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2694 - val_loss: 0.3411\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2568 - val_loss: 0.2810\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2569 - val_loss: 0.4058\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2739 - val_loss: 0.3018\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2558 - val_loss: 0.3223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2681 - val_loss: 0.2886\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2622 - val_loss: 0.2853\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2573 - val_loss: 0.3097\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2546 - val_loss: 0.3753\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2733 - val_loss: 0.2914\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2615 - val_loss: 0.2833\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2597 - val_loss: 0.3132\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.2846\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time= 1.2min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1527 - val_loss: 0.5753\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5713 - val_loss: 8.9879\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 11.0986\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5126 - val_loss: 1.1306\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.5258\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4499\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3816 - val_loss: 0.3998\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.3957\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.3903\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.3688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.3651\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.3709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3817\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.3623\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3671\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.3672\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.3606\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.3552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3536\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3381 - val_loss: 0.3519\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.3474\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3414 - val_loss: 0.3510\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3381 - val_loss: 0.3304\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3398 - val_loss: 0.3686\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3246\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.3387\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3375 - val_loss: 0.3367\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3389\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3303 - val_loss: 0.3209\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3299 - val_loss: 0.3227\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3205 - val_loss: 0.3150\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3229 - val_loss: 0.3511\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3198 - val_loss: 0.3161\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3166 - val_loss: 0.3141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3178 - val_loss: 0.3843\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3101 - val_loss: 0.3600\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3261 - val_loss: 0.3544\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3117 - val_loss: 0.3168\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3008 - val_loss: 0.3405\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3140 - val_loss: 0.3163\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3161 - val_loss: 0.3164\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3143\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3092 - val_loss: 0.3418\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3057\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3302\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3050 - val_loss: 0.3330\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2948 - val_loss: 0.3175\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3019\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.3649\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.3269\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3405\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2997 - val_loss: 0.3068\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3089\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.3346\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3000\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3056 - val_loss: 0.3707\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3018 - val_loss: 0.3165\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3063 - val_loss: 0.2981\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3177\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2890 - val_loss: 0.3231\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.3422\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3082\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2894 - val_loss: 0.4176\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.3030\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3103 - val_loss: 0.3343\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2984 - val_loss: 0.2985\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.3713\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2946 - val_loss: 0.2969\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3121 - val_loss: 0.3563\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2939 - val_loss: 0.2941\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3076 - val_loss: 0.3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.2962\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.4277\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2926\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2932 - val_loss: 0.3673\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2829 - val_loss: 0.3217\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.5634\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2969 - val_loss: 0.3334\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2839 - val_loss: 0.5032\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2779 - val_loss: 0.3119\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2750 - val_loss: 0.6628\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.6841\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2938 - val_loss: 0.8619\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.3784\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3198\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time= 1.1min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2993 - val_loss: 0.8898\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5586 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4526 - val_loss: 0.4844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4289 - val_loss: 0.4250\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.3735\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.3859\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.4576\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4928\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.5255\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.5956\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.6364\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.7456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.7136\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.6905\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3615\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  12.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 2.1229 - val_loss: 2.8528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6059 - val_loss: 2.3412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 0.9015\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4576 - val_loss: 0.8313\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.5217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.3745\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4012\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.4169\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.3843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.6122\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.3579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3399 - val_loss: 0.3497\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.5161\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.4273\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.5739\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.4975\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4886\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.3371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4118\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3310\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3289\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3287\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.5224\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.7689\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.8909\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.4864\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.6169\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 0.3470\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3346 - val_loss: 0.5750\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3685\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.7292\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3363 - val_loss: 0.3932\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3362\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  27.3s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.4598 - val_loss: 6.5088\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8145 - val_loss: 7.3062\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.5231\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3804 - val_loss: 0.3947\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.5391\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.3491\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.3398\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.3290\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.4460\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3323 - val_loss: 0.9023\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3517 - val_loss: 0.9399\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3403\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3263 - val_loss: 0.3268\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.3049\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.4244\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3026\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3336\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3000 - val_loss: 0.4325\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3078 - val_loss: 0.3407\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2956 - val_loss: 0.6759\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 1.1320\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3067 - val_loss: 0.6132\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.2987\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3023 - val_loss: 0.3811\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3011 - val_loss: 0.2994\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3017 - val_loss: 0.3678\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2907 - val_loss: 0.2900\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3018 - val_loss: 0.3994\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.3507\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2898 - val_loss: 0.4075\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2898 - val_loss: 0.2893\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2929\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2769 - val_loss: 0.3547\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2754 - val_loss: 0.3140\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3006 - val_loss: 0.3900\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2787 - val_loss: 0.3061\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2935 - val_loss: 0.3524\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2849\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2890 - val_loss: 0.3960\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2726 - val_loss: 0.2764\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.3827\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2724 - val_loss: 0.3170\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2771 - val_loss: 0.2777\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2789 - val_loss: 0.3093\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.2817\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2668 - val_loss: 0.3744\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2728 - val_loss: 0.2851\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2750 - val_loss: 0.3586\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2727 - val_loss: 0.2731\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2688 - val_loss: 0.2777\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2703 - val_loss: 0.4556\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2586 - val_loss: 0.7225\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2706 - val_loss: 1.1079\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2663 - val_loss: 0.7613\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2597 - val_loss: 0.8934\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.3215\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2672 - val_loss: 0.3987\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.2679\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2731 - val_loss: 0.3196\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2605 - val_loss: 0.3023\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2658 - val_loss: 0.2740\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.3065\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2580 - val_loss: 0.2730\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2546 - val_loss: 0.3227\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2698 - val_loss: 0.2671\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2566 - val_loss: 0.3146\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2536 - val_loss: 0.2752\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2537 - val_loss: 0.3387\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2588 - val_loss: 0.2889\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2435 - val_loss: 0.2777\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2604 - val_loss: 0.2791\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2571 - val_loss: 0.3839\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2476 - val_loss: 0.3094\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2547 - val_loss: 0.3533\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2446 - val_loss: 0.3028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001C70653ADC8>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b811375",
   "metadata": {},
   "source": [
    "The exploration may last many hours, depending on the hardware, the size of the dataset, the complexity of the model, and the values of `n_iter` and `cv`. When it’s over, you can access the best parameters found, the best score, and the trained Keras model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97904941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.0059640580092043885}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee6b6ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3177357614040375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c96141a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x1c7ee3e26c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3ced84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.2788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.2787829637527466"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56d445cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1c724888e08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0d182bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.2788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2787829637527466"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db1dd8",
   "metadata": {},
   "source": [
    "Using randomized search is not too hard, and it works well for many fairly simple problems. When training is slow, however (e.g., for more complex problems with larger datasets), this approach will only explore a tiny portion of the hyperparameter space. You can partially alleviate this problem by assisting the search process manually: first run a quick random search using wide ranges of hyperparameter values, then run another search using smaller ranges of values centered on the best ones found during the first run, and so on. This approach will hopefully zoom in on a good set of hyperparameters. However, it’s very time consuming, and probably not the best use of your time.\n",
    "\n",
    "Fortunately, there are many techniques to explore a search space much more efficiently than randomly. Their core idea is simple: when a region of the space turns out to be good, it should be explored more. Such techniques take care of the “zooming” process for you and lead to much better solutions in much less time. Here are some Python libraries you can use to optimize hyperparameters:\n",
    "* [Hyperopt](https://github.com/hyperopt/hyperopt)\n",
    "* [Hyperas](https://github.com/maxpumperla/hyperas), [kopt](https://github.com/Avsecz/kopt) or [Talos](https://github.com/autonomio/talos)\n",
    "* [Keras Tuner](https://www.youtube.com/watch?v=Un0JDL3i5Hg&t=24s)\n",
    "* [Scikit-Optimize (skopt)](https://scikit-optimize.github.io/stable/)\n",
    "* [Spearmint](https://github.com/JasperSnoek/spearmint)\n",
    "* [Hyperband](https://github.com/zygmuntz/hyperband)\n",
    "* [Sklearn-Deap](https://github.com/rsteca/sklearn-deap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b55bc2",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be9b2335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09f56224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d11fc614",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.linspace(-5, 5, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fad25",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "The sigmoid activation function is also called the logistic function.\n",
    "\n",
    "It is the same function used in the logistic regression classification algorithm.\n",
    "\n",
    "The function takes any real value as input and outputs values in the range 0 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54bf7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e23c4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.savefig(\"images/activations/sigmoid_saturation_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c8d96",
   "metadata": {},
   "source": [
    "When using the Sigmoid function for hidden layers, it is a good practice to use a “Xavier Normal” or “Xavier Uniform” weight initialization (also referred to Glorot initialization, named for Xavier Glorot) and scale input data to the range 0-1 (e.g. the range of the activation function) prior to training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e7b16",
   "metadata": {},
   "source": [
    "## Softmax function\n",
    "The softmax function outputs a vector of values that sum to 1.0 that can be interpreted as probabilities of class membership.\n",
    "\n",
    "It is related to the argmax function that outputs a 0 for all options and 1 for the chosen option. Softmax is a “softer” version of argmax that allows a probability-like output of a winner-take-all function.\n",
    "\n",
    "As such, the input to the function is a vector of real values and the output is a vector of the same length with values that sum to 1.0 like probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4abdf059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "\treturn np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c19837",
   "metadata": {},
   "source": [
    "Target labels used to train a model with the softmax activation function in the output layer will be vectors with 1 for the target class and 0 for all other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5dc5a2",
   "metadata": {},
   "source": [
    "## Hyperbolic Tangent (Tanh) function\n",
    "The hyperbolic tangent activation function is also referred to simply as the Tanh (also “tanh” and “TanH“) function.\n",
    "\n",
    "It is very similar to the sigmoid activation function and even has the same S-shape.\n",
    "\n",
    "The function takes any real value as input and outputs values in the range -1 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to -1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "446aa025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return ((np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d17b7f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -1.2, 1.2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, tanh(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.grid(True)\n",
    "plt.title(\"Tanh activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.savefig(\"images/activations/tanh_saturation_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f332d",
   "metadata": {},
   "source": [
    "When using the TanH function for hidden layers, it is a good practice to use a “Xavier Normal” or “Xavier Uniform” weight initialization (also referred to Glorot initialization, named for Xavier Glorot) and scale input data to the range -1 to 1 (e.g. the range of the activation function) prior to training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d42b7",
   "metadata": {},
   "source": [
    "## Rectified Linear Unit (ReLU) function\n",
    "The rectified linear activation function, or ReLU activation function, is perhaps the most common function used for hidden layers.\n",
    "\n",
    "It is common because it is both simple to implement and effective at overcoming the limitations of other previously popular activation functions, such as Sigmoid and Tanh. Specifically, it is less susceptible to *vanishing gradients* that prevent deep models from being trained, although it can suffer from other problems like saturated or “dead” units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49344b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "\treturn max(0.0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33d50f",
   "metadata": {},
   "source": [
    "When using the ReLU function for hidden layers, it is a good practice to use a “He Normal” or “He Uniform” weight initialization and scale input data to the range 0-1 (normalize) prior to training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01586be6",
   "metadata": {},
   "source": [
    "## Leaky ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d052dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "600c7734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEJCAYAAAC9uG0XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hU1b3/8fcXwiVIEGwEEam0XgEtoIi1KuINOQS11npBRZAi2nqlYrUqam2pF9RiwSuCiFwt6vNrldMqxVDp4aBAsRYVj1JEEEGKkYRbSLJ+f6yJGUIuk5DJ2jPzeT3PPOyZ2dn7MyszX1bWrL23OecQEZHoahI6gIiI1EyFWkQk4lSoRUQiToVaRCTiVKhFRCJOhVpEJOJUqFOEmTkz+3HoHKnMzIaZWVEj7atRfl9mdrKZ/dPMis0sP9n7qyVLl9jr7h0yRzpSoW4AZjbVzF4NnaMuzOze2IfKmVmZmX1uZjPMrHMdt5NvZhOreW6NmY2uZt//qm/2BHNVVSjnAN9t4P1U97vvCPypIfdVjceAd4HDgB81wv6Aan/vn+Ff94rGypEpVKgz2yr8B+sQ4BLgWODFoImSyDm3wzm3qZH29YVzblcj7OpwYIFz7jPn3JZG2F+1nHOlsdddEjJHOlKhbgRm1s3MXjOzQjPbZGazzOyguOdPMLPXzWyzmW01s0VmdlIt27wttv5psZ/5caXnzzaz3WbWoYbNlMQ+WJ87594CJgHfN7M2cds518yWmdlOM/u3mY01s+b1bIqEmFlTM5sc298OM/s/M/uFmTWptN5QM3vPzHaZ2UYzmxp7fE1slT/EetZrYo9/M/RhZkfGnju20jZHxtq1WW05zOxeYCiQF/fXSb/Yc3v06M3sWDObH9vOllhPfP+456ea2atmdpOZrTezr8zsOTNrVU0bdTEzB+wPTIntb5iZ9Yst51Zet3xIIm6dM81siZltN7OlZnZcpX1838wWmNk2M/vazP5qZgfH2vk04Lq4192lqqEPM+sb28fO2O/od/Hvn1jP/Akz+22s3TeZ2cOVf9eZTo2RZGbWEfgb8C+gD3AW0Br4Y9ybMQd4ATg1ts4KYF78hy1ue2ZmDwM3AKc55xYCs4DhlVYdDrzqnNuYYM6D8H86l8ZumNk5wAxgItA9ts0fA79N6MXXXxNgPXAx0BW4E7gDuCou7zXA08BzwPeAgcDK2NMnxP69Gv8XQ/n9bzjnPgKWApdXeupyYI5zbncCOR7G/wUyP7afjsD/VN5XrNj+GSjC/34vAH4ATKm06qnAMfj3yCWx9W6qvL2Y8mGG7cDNseU51axbnfuB24HjgP8AM8zMYpl7AG8CHwMnA9+PvdasWKbF+LYvf92fVfG6OwH/DfwD6AX8BBgc22+8y4ESfJtcH3s9l9TxtaQ355xu+3gDpuKLYlXP3Qf8tdJj7QAH9KnmZwzYAFwR95jDv3mfAz4CusQ91xv/Ru8Ut/0dwKAaMt+LL8hF+A+7i90ei1vnb8CYSj/3w9jPWOx+PjCxmn2sAUZXs+9/1bGNHwDmx91fBzxQw/oO+HGlx4YBRXH3bwI+jXstnYEy4KQ65Kjydx+/f/x/GF8DOXHP94utc3jcdj4DsuLWmRS/r2ryFAHDqthubtxjXWKP9a60zjlx65wce+yQ2P0ZwP/WsN+9fu9V7GcsvtA3qfQ72AW0itvO4krbeQN4dl8+k+l2U486+Y4H+ppZUfmNit7HYQBm1t7Mnjazj8zsa6AQaA98u9K2HsZ/yE5xzq0pf9A5txR4D/9nOMBlwFf43kxNPgF64nucdwLL8T3G+Ox3Vso+E9gPOKjyxhqSmV0b+3P8y9h+RxFrDzNrD3QC/rqPu5kFHIzvyYJvt9XOucWJ5KiDrsA/nXOFcY/9D/4/hW5xj73v9hzf/Rz/PkiWf1baF3H768W+t29XfBEui3tsEdAcP7ZeVY7yLMl83SlHhTr5mgCv4Qti/O0IoHy2wPP4YjkK/+dfT3yPsfJY8Bv4Ajmwiv08S8Wf5MOBqc650lqyFTvnPnbOrXTO/Rb/gXm8UvZfVcr9vVj2L2vZNsBW/BhqZW3xPcwqmdklwHh8L/Oc2H6foKI9LIF918r5LxbnUzH8cTm+J5lojkQZvqdZZYy45d1VPFfXz2h5UYxvo2bVrBu/v/Ic5ftriDZuzNed1rJCB8gAy/FjnJ86P+5ZlVOAG51zrwGY/wKwYxXrzQNeJvYlmXPu+bjnpgPjzOx6/JjjpfXI+mtglZlNcM4ti2U/2jn3cT22BX5WyfFVPH5c7LnqnAIscc59M/3LzA4rX3bObTSz9cCZ+P+8qrIbaJpAxunABDN7Bj/r5cJEc8QUJ7Cf94HhZpYT16v+Ab4YfZBAxroo/w+0Y9xyz3psZzlwRg3PJ/q6LzazJnG96lNiP/tJPTJlLP2v1XDamFnPSrcu+B7q/sAcMzvRzL5rZmeZ2TNmlhP72Y+AK8zPDjkBmI1/M+/FOfcqcBHwlJldGff418AfgEeAvznn/q+uL8A5txr4I75ggx9fv8zM7jOzY8zsaDP7sZk9VOlHc6t47QcDvwPOMbMxsdfW3czGAifhe6rV+Qg4zsz+y8yOMLMx+FkG8cYCN5vZKPMzOHqa2S1xz68BzjSzg8ysXQ37egXf45wMvF2p3RLJsQY4xsyOMrNcM6uq9zoD2AZMMz/7oy/+i9CX9+E/wep8jB9auzfWLv2Bu+qxnXFAr9j7tEfs9Y0ws/JhnzVAn9hMj9xqZmk8gR9aesLMuppZHn6Mf6Jzbns9MmWu0IPk6XDD/2nsqrjNjT1/BDAXP268A9+bnAA0jz3fA1gSe+4TYAh+lsi9cfvY48sx4NzY+lfGPdY3tt6VCWS+lyq+0MP39Bzwg9j9/sBb+C8ct+JnSlwft35+Na/94Uo/vwU/syAf6FtLtub4wvkVUBBbvhtYU2m9n+B7bcXAF8CUSu3zf/ie9ZrYY8OI+zIxbt1pscw31DUHcCDwOv57BQf0q+b3dSx+zHdHbHtTgf0rvYderbT/Kn9HldbZ48vEuN/hiti+FgN5VP1lYrVfOMYeOwX/hfKO2OufD3SMPXdkbNvlX0R3qWYbffHv7V3ARvx/3i0qvX8qfym5V1tk+q38225JA7Ex1aeBg516LCJpQ2PUaSA2T7cLfsbGJBVpkfSiMer08Av8+R62UDG+LCJpQkMfIiIRpx61iEjEJWWMOjc313Xp0iUZm07Ytm3b2G+//YJmiAq1hbdq1SpKS0vp1q1b7StnAL0vKlTVFh99BIWF0KYNHHFE8jMsW7Zss3PuwKqeS0qh7tKlC0uXLk3GphOWn59Pv379gmaICrWF169fPwoKCoK/N6NC74sKldvi/vvhjjugfXv45z+hQ03noGwgZvZpdc9p6ENEJM6SJTBmjF9+/vnGKdK1UaEWEYn5+msYPBhKS+HnP4cBA0In8lSoRUQA5+BnP4N//xt69YLfJvus63WgQi0iArzwAsycCa1awaxZ0KJF6EQVEi7U5i9L9A9LsYu4iojUZv36bK67zi9PmABHHRU2T2V16VHfRMOfklFEJKjiYvj1r7tSVASXXAJXXVX7zzS2hAq1mR2CPwPXs8mNIyLSuO66C1atasOhh8JTT4E1yGUpGlaiPerx+PNJlNW2oohIqnjjDRg3Dpo0ccycCW3bhk5UtVoPeDGzQcAm59wyM+tXw3ojgZEAHTp0ID8/v6Ey1ktRUVHwDFGhtvAKCgooLS1VW8Rk+vuioKAZP/lJb6AFgwd/RHHxBqLaHIkcmXgycJ6ZDQRa4q9kMt05d0X8Ss65Z4BnAHr37u1CH/Gko64qqC28tm3bUlBQoLaIyeT3hXMwaBBs2QJ9+8JVV22IdFvUOvThnPulc+4Q51wX/HX4FlQu0iIiqeT3v4d586BdO5g+HZomcnXNgDSPWkQyyooV8Itf+OXJk6Fz57B5ElGnkzI55/Lx1zgTEUk527b5Q8SLi+Gaa+CCC0InSox61CKSMUaNgg8/hG7d4NFHQ6dJnAq1iGSEuXNh0iR/aPjs2f5Q8VShQi0iaW/tWrj6ar/88MNw7LFh89SVCrWIpLWSErj8cigogHPP5ZtzeqQSFWoRSWtjx8KiRdCxI0yZEs1DxGujQi0iaeutt+C++3xxnj4dcnNDJ6ofFWoRSUtffeWHPMrK4Lbb4IwzQieqPxVqEUk7zsHIkfDZZ9Cnj+9VpzIVahFJO5Mn++l4OTn+ai3NmoVOtG9UqEUkrXzwAdx4o19+8kn47nfD5mkIKtQikjZ27vSHiO/YAUOG+DHqdKBCLSJp4/bb4d134fDD4fHHQ6dpOCrUIpIWXnsNHnsMsrL81cRzckInajgq1CKS8jZsgGHD/PLYsXDCCUHjNDgVahFJaWVlcOWVsHkznHUWjB4dOlHDU6EWkZT2yCMwf74/6nDaNGiShlUtDV+SiGSKd96BO+7wy1On+vN5pCMVahFJSYWFfipeSYmfN52XFzpR8qhQi0hKuv56+OQT6NEDHnwwdJrkUqEWkZQzY4Yfj87O9oeIt2wZOlFyqVCLSEpZvRp++lO//Nhj0LVr2DyNQYVaRFLG7t1+XLqwEC68EEaMCJ2ocahQi0jKuOceePtt6NzZX6g2Fa/WUh8q1CKSEhYsgAce8POkZ8yAdu1CJ2o8KtQiEnmbN8MVV/gLAowZA6eeGjpR41KhFpFIcw6GD/fn8zj5ZLjrrtCJGp8KtYhE2hNPwJ/+BPvv74c8srJCJ2p8KtQiElnvvQe33OKXJ02CQw8NmycUFWoRiaTt2+HSS2HXLj8N76KLQicKR4VaRCLpllvg/ffh6KNh/PjQacJSoRaRyHnlFXjqKWje3B8ivt9+oROFpUItIpHy2Wfwk5/45Ycegp49w+aJAhVqEYmM0lJ/9fCvvoKBA/3pS0WFWkQi5P77YeFC6NABnnsucw4Rr40KtYhEwuLFcO+9fvmFF6B9+6BxIkWFWkSCKyjwZ8UrLYVbb4Wzzw6dKFpUqEUkKOfg2mvh00+hd2/4zW9CJ4oeFWoRCWrqVJgzx0/BmznTT8mTPdVaqM2spZm9bWbvmtlKM/tVYwQTkfS3ahXccINffuIJOOKIsHmiKpHTm+wCznDOFZlZM2CRmf23c+5/k5xNRNLYrl1+XHrbNrjsMj8tT6pWa6F2zjmgKHa3WezmkhlKRNLfHXfAP/4B3/kOPPmkpuLVJKETBppZU2AZcDjwuHNuSRXrjARGAnTo0IH8/PwGjFl3RUVFwTNEhdrCKygooLS0VG0RE/J98fbbB/Doo9+jSRPH6NH/YPnyrUFylIv8Z8Q5l/ANaAu8CRxT03rHH3+8C+3NN98MHSEy1Bbeaaed5nr06BE6RmSEel988YVz7ds7B8799rdBIuwlCp8RYKmrpqbWadaHc64AyAcGNPR/GCKS/srKYOhQ2LQJTj8dfvGL0IlSQyKzPg40s7ax5WzgLODDZAcTkfQzfjz85S/wrW/5ow+bNg2dKDUkMkbdEXg+Nk7dBHjROfdqcmOJSLpZvhxuv90vT54MnTqFzZNKEpn18U+gVyNkEZE0VVTkp+Lt3g3XXQfnnx86UWrRkYkiknQ33ggffQTHHAPjxoVOk3pUqEUkqebM8acsbdkSZs+G7OzQiVKPCrWIJM2aNTBypF9+9FHo3j1onJSlQi0iSVFS4g8N37oVfvhDf4Y8qR8VahFJil/9yl8MoFMnePZZHSK+L1SoRaTBLVwIY8f64jx9up83LfWnQi0iDWrLFrjiCn9BgDvvhH79QidKfSrUItJgnIMRI2DdOjjpJLjnntCJ0oMKtYg0mKefhldegTZt/NVashI6P6fURoVaRBrEypUwapRffvpp6NIlaJy0okItIvts505/iPjOnXDVVXDppaETpRcVahHZZ7feCu+9B0ceCb//feg06UeFWkT2yR//CBMnQrNmMGsWtG4dOlH6UaEWkXpbvx6GD/fL998Pxx0XNk+6UqEWkXopLYUrr4T//AfOOafii0RpeCrUIlIv48bBggXQvj08/zw0UTVJGjWtiNTZkiVw111++fnnoUOHsHnSnQq1iNTJ1q1+Kl5pqR/uGKBLXSedCrWIJMw5+OlP4d//hl69/BeIknwq1CKSsBde8IeGt2rlp+K1aBE6UWZQoRaRhHz8sb8wLcCECXDUUWHzZBIVahGpVXGxH5cuKoKLL/aHiUvjUaEWkVqNGQNLl8Khh/oTLulqLY1LhVpEavTGG/DQQ9C0qR+fbts2dKLMo0ItItX68kt/9CH4iwD84Adh82QqFWoRqZJzfiz6iy+gb1+4447QiTKXCrWIVGnCBHjtNWjXzl+gtmnT0Ikylwq1iOxlxQp/jmmAyZOhc+eweTKdCrWI7GHbNj8Vr7gYrrkGLrggdCJRoRaRPYwaBR9+CN26waOPhk4joEItInHmzoVJk/yh4bNn+0PFJTwVahEBYO1auPpqv/zww3DssWHzSAUVahGhpAQuvxwKCuDccyvO6SHRoEItIowdC4sWQceOMGWKDhGPGhVqkQy3aBHcd58vztOnQ25u6ERSmQq1SAb76iu47DIoK4PbboMzzgidSKqiQi2SoZyDkSPhs8+gTx/fq5ZoqrVQm1lnM3vTzD4ws5VmdlNjBBOR5Jo3ryNz50JOjj8rXrNmoRNJdbISWKcEuMU5t9zMcoBlZvaGc+79JGcTkST54AOYOPFwAJ58Eg47LHAgqVGtPWrn3Abn3PLYciHwAdAp2cFEJDl27vSHiO/c2ZQhQ/y0PIm2RHrU3zCzLkAvYEkVz40ERgJ06NCB/Pz8fU+3D4qKioJniAq1hVdQUEBpaWnGt8XEiYfz7ruH0LHjNi69dDn5+aWhIwUX9c9IwoXazFoDLwE3O+e2Vn7eOfcM8AxA7969Xb9+/RoqY73k5+cTOkNUqC28tm3bUlBQkNFtMW8evPQSZGXB3Xd/yMCBp4aOFAlR/4wkNOvDzJrhi/QM59zLyY0kIsmwYQMMG+aXx46Fo48uDJpHEpfIrA8DJgMfOOd0Li2RFFRW5i+p9eWXcNZZMHp06ERSF4n0qE8GhgBnmNmK2G1gknOJSAN65BGYP98fdThtGjTRERQppdYxaufcIkBH/oukqHfeqbje4dSp/nweklr0/6pIGiss9FPxSkrgxhshLy90IqkPFWqRNHb99fDJJ9CjBzz4YOg0Ul8q1CJpauZMPx6dnQ2zZkHLlqETSX2pUIukodWr4dpr/fJjj0HXrmHzyL5RoRZJM7t3+3HpwkK48EIYMSJ0ItlXKtQiaeaee+Dtt6FzZ3+hWl2tJfWpUIukkQUL4IEH/DzpGTOgXbvQiaQhqFCLpInNm2HIEH9BgDFj4FSdxiNtqFCLpAHnYPhw+PxzOPlkuOuu0ImkIalQi6SBJ56AP/0J9t/fD3lk1ekExhJ1KtQiKe699+CWW/zypElw6KFh80jDU6EWSWHbt/upeLt2+Wl4F10UOpEkgwq1SAq75RZYuRKOPhrGjw+dRpJFhVokRb3yCjz1FDRv7g8R32+/0IkkWVSoRVLQunUVRxw+9BD07Bk2jySXCrVIiikthSuugC1bYOBAf/pSSW8q1CIp5v77YeFC6NABnntOh4hnAhVqkRSyeDHce69fnjYN2rcPGkcaiQq1SIr4+mu47DI/9HHrrdC/f+hE0lhUqEVSgHNwzTWwZg307g2/+U3oRNKYVKhFUsDUqTBnjp+CN3Omn5InmUOFWiTiPvoIbrjBLz/+OBxxRNg80vhUqEUibNcuf4j4tm1+fPrKK0MnkhBUqEUi7M47Yfly+M534MknNRUvU6lQi0TUn/8MjzwCTZv6cek2bUInklBUqEUiaONGGDrUL993H3z/+2HzSFgq1CIRU1YGw4bBpk1w+ulw222hE0loKtQiETN+vB/2+Na34IUX/NCHZDYVapEIWb4cbr/dL0+eDJ06hc0j0aBCLRIRRUV+Kt7u3XDddXD++aETSVSoUItExE03+YNbjjkGxo0LnUaiRIVaJALmzIEpU6BlS5g9G7KzQyeSKFGhFglszRoYOdIvP/oodO8eNI5EkAq1SEAlJf7Q8K1b4Yc/hGuvDZ1IokiFWiSg++7zFwPo1AmefVaHiEvVVKhFAlm40J9X2gymT/fzpkWqokItEsCWLf4Ctc7BHXdAv36hE0mU1VqozWyKmW0ys381RiCRdOccjBgB69bBSSfBPfeETiRRl0iPeiowIMk5RDLGM8/AK6/4s+HNnAnNmoVOJFFXa6F2zv0N2NIIWUTS3sqVcPPNfvnpp6FLl6BxJEVkNdSGzGwkMBKgQ4cO5OfnN9Sm66WoqCh4hqhQW3gFBQWUlpYGa4vi4ib89KfHsXNnawYM2MBBB60i5K9F74sKUW+LBivUzrlngGcAevfu7foF/nYkPz+f0BmiQm3htW3bloKCgmBtccMNsHq1v+bhH/7QkdatOwbJUU7viwpRbwvN+hBpBH/6E0yc6MejZ8+G1q1DJ5JUokItkmTr18NVV/nl+++H444Lm0dSTyLT82YBi4GjzGydmf0k+bFE0kNpqb9y+H/+A/37w6hRoRNJKqp1jNo5N7gxgoiko3HjYMECaN8enn8emuhvWKkHvW1EkmTJEhgzxi8//zwcdFDYPJK6VKhFkmDrVn+1lpISP9wxQIeMyT5QoRZJgp/9DP79b+jVy3+BKLIvVKhFGtgLL8CMGdCqFcyaBS1ahE4kqU6FWqQBffyx700DTJgARx0VNo+kBxVqkQZSXOzHpYuK4OKLK+ZOi+wrFWqRBjJmDCxdCoce6k+4pKu1SENRod5HZsbcuXNDx5DA3ngDHnoImjb1py5t2zZ0IkknaV+ohw0bxqBBg0LHkDT25Zf+6EPwFwH4wQ/C5pH0k/aFWiSZnPNj0V98AX37+stqiTS0jC7U77//Pnl5eeTk5NC+fXsGDx7MF1988c3z77zzDv379yc3N5c2bdpwyimnsHjx4hq3+eCDD5Kbm8uSJUuSHV8iYMIEeO01aNfOX6C2adPQiSQdZWyh3rBhA3379uWYY47h7bffZv78+RQVFXHeeedRVlYGQGFhIUOGDOGtt97i7bffpmfPngwcOJDNmzfvtT3nHKNHj2bChAksXLiQE088sbFfkjSyd9+FW2/1y5MnQ+fOYfNI+mqwCwekmieffJIePXrw4IMPfvPYtGnTOOCAA1i6dCl9+vThjDPO2ONnJkyYwEsvvcSf//xnrrjiim8eLy0tZfjw4fz9739n0aJFdNH1ldLetm1w6aV+St4118AFF4ROJOksYwv1smXL+Nvf/kbrKs7g/sknn9CnTx82bdrEmDFjePPNN9m4cSOlpaXs2LGDtWvX7rH+6NGjycrKYsmSJbRv376xXoIENGoUfPghdOsGjz4aOo2ku4wt1GVlZeTl5fHwww/v9VyHDh0AGDp0KBs3buR3v/sdXbp0oUWLFpx55pkUFxfvsf7ZZ5/NrFmzmDdvHsOGDWuM+BLQ3LkwaZI/NHzWLH+ouEgyZWyhPu6443jxxRc59NBDadasWZXrLFq0iN///vfk5eUBsHHjRjZs2LDXegMHDuRHP/oRF110EWbG0KFDk5pdwlm7Fq6+2i8//DB873th80hmyIgvE7du3cqKFSv2uOXl5fH1119zySWXsGTJElavXs38+fMZOXIkhYWFABx55JFMnz6d999/n3feeYdLL72U5s2bV7mPQYMG8Yc//IFrr72WadOmNebLk0ZSUgKXXw4FBXDuuXDddaETSabIiB71W2+9Ra9evfZ47MILL+Tvf/87v/zlLxkwYAA7d+7k29/+Nv3796dF7HRnU6ZMYeTIkRx//PEcfPDB3HvvvXz55ZfV7mfQoEG8+OKLXHzxxQBcWX4UhKSFsWNh0SLo2BGmTNEh4tJ40r5QT506lalTp1b7fE2Hf/fo0WOv+dBDhgzZ475zbo/75557Ljt27Kh7UIm0RYvgvvt8cX7hBcjNDZ1IMklGDH2I7IuvvvJDHmVlcNttcOaZoRNJplGhFqmBczBypP8SsU8f36sWaWwq1CI1mDzZT8fLyfFnxatmgpBIUqlQi1Tjww/hppv88pNPwmGHhc0jmStlC/WmTZs477zzWLp0aegokoZ27vSHiG/fDkOG+DFqkVBSslCvWrWKHj16MG/ePM4++2w+/fTT0JEkzdx+uz/p0mGHweOPh04jmS7lCvVbb73FCSec8M25N7Zu3cppp51GQUFB6GiSJubNg8ceg6wsf4h4Tk7oRJLpUqpQz5w5k3POOYfCwsJv5i+XlZWxfv16RowYETidpIMNG6D8dC1jx8IJJwSNIwKkSKF2zvHrX/+aESNG7HUwiZmRnZ3NqFGjAqWTdFFWBkOH+ktrnXUWjB4dOpGIF/kjE0tKShg+fDgvvfTSXkU6KyuLAw88kPz8fI488shACSVdPPKIv0htbi5MmwZNUqIbI5kg0oW6sLCQvLw8li1bxvbt2/d4rmXLlhxxxBH89a9/5cADDwyUUNLF0qUV1zucOtWfz0MkKiJbqD///HP69evH2rVr2bVr1x7PtWrVir59+/Lyyy+TnZ0dKKGki8JCGDzYnx3vxhshdlZbkciI5B937733Hj169GD16tVVFulhw4bx6quvqkhLg7j+evj4Y+jRA+KuzCYSGZEr1K+//jonnXQSmzdvprS0dI/nsrOz+c1vfsPjjz9OU13uWRrAzJl+PDo720/Fa9kydCKRvUVq6GPSpEncdNNNVZ4mtFWrVsycOZPzzz8/QDJJR6tXw7XX+uXHHoOuXcPmEalOo/eon332WQYPHkxZWdk3jznnuO2227j55pv3KtJNmjShbdu25Ofnq0hLg9m9Gy67zI9PX3ghaBq+RFmjFuqysjLuvvtuXn75ZX7+858DUFxczEUXXcTEiRP3mtnRvHlzDjnkEJYvX84JOvJAGtA998CSJdC5s79Qra7WIlHWqEMfCxYsoLCwkOLiYiZNmsRBBx3Eyy+/zL/+9a+9etLZ2dl0796d119/nXbt2jVmTElzCxbAAw/4edIzZoDeXhJ1jVqox40bR1FREQDbt2/nnnvuAXyvOl6rVq0YMGAAM5mHlKgAAAdDSURBVGfO/Ob6hSINoaTEGDLEXxDg7rvh1FNDJxKpXUJDH2Y2wMxWmdnHZnZ7fXa0bt06Fi5cuMdjxcXFVRbp66+/nrlz56pIS4NyDj77rBWffw4nnwx33RU6kUhiau1Rm1lT4HHgbGAd8I6Z/dE5935ddvTEE0/Uuk52djbjx4/n6quvrsumRaq0a5e/3uGWLbBpE6xYAVu3NmP//f2QR1ak5jyJVM8qX0V7rxXMTgLudc6dE7v/SwDn3P3V/UxOTo47/vjjv7lfVlbG4sWLKSkpqXFfXbt2pX379omnr0FBQQFt27ZtkG2lulRvi5KSitvu3VX/W9VjcROLYlYA0LNnT/bfv9FfRuSk+vuiIUWhLRYuXLjMOde7qucS6VN0Aj6Lu78OOLHySmY2EhgJ0KxZsz3OD11QULDHdLyqmBmffvopWVlZNGmAs+GUlpbqHNUxUWgL56C0tAklJUZpqb/FL+95f8/19kVWlqNp0zKaNnUUFzuaNSvFuQL01ojG+yIqot4WiRTqqj4pe3XDnXPPAM8A9O7d28VfIuuEE06o9Soszjmcc3Tt2pXZs2dj+zhfKj8/n379+u3TNtJFQ7WFc37e8ZYt/lY+rJDI8rZt9d9vTg4ccIC/tWuX+PJ+++057a5fv34UFBSwYsWKfW6LdKDPSIUotEVNNS+RQr0O6Bx3/xDg80R3/sEHH7By5cqE1t21axcvvvgil19+Oeedd16iu5A6Ki72BbQuhbZ8udJR/QnLyqp7oT3gAGjbVlf+FkmkUL8DHGFm3wHWA5cClyW6g/Hjx7N79+4qnzMzcnJy2LFjB4cffjiDBg3inHPOoW/fvoluPmM5B0VFiRXX1at7UFZWcT82Q7JeWreuW6Etv9+6tQ4qEamvWgu1c67EzK4H/gI0BaY45xLqIm/bto3p06fv8SViTk4Ou3btolOnTuTl5TFgwABOPfVU2rRpU9/XkNJ27665d1tdEf7qK/+FWWL2PKKjadP6926bN2/wJhCRWiQ0Qck5Nw+YV9eNz5kzh507d9KiRQtyc3Pp378/eXl5nHbaaeTm5tY5bFQ558dg61Joy5cLC+u/3/32S6zQrl27gjPO6PnN4zk56t2KpJKkziQ98cQTmTZtGqeffjoHH3xwMnfVIEpK9u7dJjp+m3jvdk9NmtSvd9uuXeK92/z8Anr1ql8+EQkvqYW6e/fudO/ePZm72Et573bTpha8+27dvijburX++23Vqn5jtzk5ujafiNQsssdmlZRAQUHdp4Ft2eLHfeGkOu+zSRNfPOtSaMv/1dHuIpIsSS3UzsH27fWbBvb11/Xfb3Y27LffLjp2bFGnotumjXq3IhI9SSnUK1f6qzhv2eLn7NaHWf17ty1bQn7+4uAT2EVEGkJSCvXOnfDFF365Zcu6Fdry5f33V+9WRASSVKi7dYM33vAFVxcKFxHZN0kp1NnZkAKz8UREUoIGF0REIk6FWkQk4lSoRUQiToVaRCTiVKhFRCJOhVpEJOJUqEVEIk6FWkQk4lSoRUQizpzb64Li+75Rsy+Bmi87nny5wObAGaJCbVFBbVFBbVEhCm1xqHPuwKqeSEqhjgIzW+qc6x06RxSoLSqoLSqoLSpEvS009CEiEnEq1CIiEZfOhfqZ0AEiRG1RQW1RQW1RIdJtkbZj1CIi6SKde9QiImlBhVpEJOIyolCb2Wgzc2aWGzpLKGY2zsw+NLN/mtkrZtY2dKbGZGYDzGyVmX1sZreHzhOKmXU2szfN7AMzW2lmN4XOFJqZNTWzf5jZq6GzVCftC7WZdQbOBtaGzhLYG8AxzrnvAR8Bvwycp9GYWVPgceC/gG7AYDPrFjZVMCXALc65rsD3gesyuC3K3QR8EDpETdK+UAO/A34BZPS3ps65151zJbG7/wscEjJPI+sDfOycW+2cKwZmA+cHzhSEc26Dc255bLkQX6A6hU0VjpkdAuQBz4bOUpO0LtRmdh6w3jn3bugsETMc+O/QIRpRJ+CzuPvryODiVM7MugC9gCVhkwQ1Ht+RKwsdpCZJuQp5YzKz+cBBVTx1J3AH0L9xE4VTU1s45/5fbJ078X/+zmjMbIFZFY9l9F9YZtYaeAm42Tm3NXSeEMxsELDJObfMzPqFzlOTlC/UzrmzqnrczI4FvgO8a2bg/9RfbmZ9nHNfNGLERlNdW5Qzs6HAIOBMl1kT6NcBnePuHwJ8HihLcGbWDF+kZzjnXg6dJ6CTgfPMbCDQEmhjZtOdc1cEzrWXjDngxczWAL2dc6HPkBWEmQ0AHgVOc859GTpPYzKzLPwXqGcC64F3gMuccyuDBgvAfK/leWCLc+7m0HmiItajHu2cGxQ6S1XSeoxa9jARyAHeMLMVZvZU6ECNJfYl6vXAX/Bfnr2YiUU65mRgCHBG7H2wItajlAjLmB61iEiqUo9aRCTiVKhFRCJOhVpEJOJUqEVEIk6FWkQk4lSoRUQiToVaRCTi/j/WH5INeW6x0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.savefig(\"images/activations/leaky_relu_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c30a2",
   "metadata": {},
   "source": [
    "## Parametric Leaky ReLU (PReLU) function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf2497",
   "metadata": {},
   "source": [
    "## ELU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc496ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58edd7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.savefig(\"images/activations/elu_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53267e",
   "metadata": {},
   "source": [
    "## SELU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "572e4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb627f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d9cd75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.savefig(\"images/activations/selu_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a4baf",
   "metadata": {},
   "source": [
    "## How to choose activation?\n",
    "* Activation functions are a key part of neural network design. \n",
    "* The modern default activation function for hidden layers is the ReLU function. \n",
    "* The activation function for output layers depends on the type of prediction problem.\n",
    "\n",
    "### Activation for Hidden Layers\n",
    "A hidden layer in a neural network is a layer that receives input from another layer (such as another hidden layer or an input layer) and provides output to another layer (such as another hidden layer or an output layer). A neural network may have zero or more hidden layers. Typically, a differentiable nonlinear activation function is used in the hidden layers of a neural network. This allows the model to learn more complex functions than a network trained using a linear activation function.\n",
    "\n",
    "There are perhaps three activation functions you may want to consider for use in hidden layers; they are:\n",
    "* Rectified Linear Activation (ReLU)\n",
    "* Logistic (Sigmoid)\n",
    "* Hyperbolic Tangent (Tanh)\n",
    "This is not an exhaustive list of activation functions used for hidden layers, but they are the most commonly used.\n",
    "\n",
    "A neural network will almost always have the same activation function in all hidden layers.\n",
    "\n",
    "It is most unusual to vary the activation function through a network model.\n",
    "\n",
    "Traditionally, the sigmoid activation function was the default activation function in the 1990s. Perhaps through the mid to late 1990s to 2010s, the Tanh function was the default activation function for hidden layers.\n",
    "\n",
    "Both the sigmoid and Tanh functions can make the model more susceptible to problems during training, via the so-called vanishing gradients problem.\n",
    "\n",
    "The activation function used in hidden layers is typically chosen based on the type of neural network architecture.\n",
    "\n",
    "Modern neural network models with common architectures, such as MLP and CNN, will make use of the ReLU activation function, or extensions.\n",
    "\n",
    "Recurrent networks still commonly use Tanh or sigmoid activation functions, or even both. For example, the LSTM commonly uses the Sigmoid activation for recurrent connections and the Tanh activation for output.\n",
    "* **Multilayer Perceptron (MLP)**: ReLU activation function.\n",
    "* **Convolutional Neural Network (CNN)**: ReLU activation function.\n",
    "* **Recurrent Neural Network**: Tanh and/or Sigmoid activation function.\n",
    "\n",
    "If you’re unsure which activation function to use for your network, try a few and compare the results.\n",
    "\n",
    "### Activation for Output Layers\n",
    "The output layer is the layer in a neural network model that directly outputs a prediction.\n",
    "\n",
    "All feed-forward neural network models have an output layer.\n",
    "\n",
    "There are perhaps three activation functions you may want to consider for use in the output layer; they are:\n",
    "* Linear\n",
    "* Logistic (Sigmoid)\n",
    "* Softmax\n",
    "\n",
    "This is not an exhaustive list of activation functions used for output layers, but they are the most commonly used.\n",
    "\n",
    "You must choose the activation function for your output layer based on the type of prediction problem that you are solving.\n",
    "\n",
    "Specifically, the type of variable that is being predicted.\n",
    "\n",
    "For example, you may divide prediction problems into two main groups, predicting a categorical variable (classification) and predicting a numerical variable (regression).\n",
    "\n",
    "If your problem is a regression problem, you should use a linear activation function.\n",
    "\n",
    "* **Regression**: One node, linear activation.\n",
    "\n",
    "If your problem is a classification problem, then there are three main types of classification problems and each may use a different activation function.\n",
    "\n",
    "Predicting a probability is not a regression problem; it is classification. In all cases of classification, your model will predict the probability of class membership (e.g. probability that an example belongs to each class) that you can convert to a crisp class label by rounding (for sigmoid) or argmax (for softmax).\n",
    "\n",
    "If there are two mutually exclusive classes (binary classification), then your output layer will have one node and a sigmoid activation function should be used. If there are more than two mutually exclusive classes (multiclass classification), then your output layer will have one node per class and a softmax activation should be used. If there are two or more mutually inclusive classes (multilabel classification), then your output layer will have one node for each class and a sigmoid activation function is used.\n",
    "\n",
    "* **Binary Classification**: One node, sigmoid activation.\n",
    "* **Multiclass Classification**: One node per class, softmax activation.\n",
    "* **Multilabel Classification**: One node per class, sigmoid activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e04a4a",
   "metadata": {},
   "source": [
    "# The Vanishing/Exploding Gradients Problems\n",
    "the backpropagation algorithm works by going from the output layer to the input layer, propagating the error gradient along the way. Once the algorithm has computed the gradient of the cost function with regard to each parameter in the network, it uses these gradients to update each parameter with a Gradient Descent step.\n",
    "\n",
    "* **Vanishing gradients problem**: gradients often get *smaller and smaller* as the algorithm progresses down to the lower layers. As a result, the Gradient Descent update leaves the lower layers’ connection weights virtually unchanged,\n",
    "and training never converges to a good solution. \n",
    "\n",
    "* **Exploding gradients problem**: the gradients can grow *bigger and bigger* until layers get insanely large weight updates and the algorithm diverges."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "850e0682",
   "metadata": {},
   "source": [
    "# Glorot and He Initialization\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13932f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
